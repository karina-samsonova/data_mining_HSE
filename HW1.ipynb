{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><img src=\"img/logo_hse.png\" width=\"1000\"></center>\n",
    "\n",
    "<h1><center>Прикладные задачи анализа данных</center></h1>\n",
    "<h2><center>Домашнее задание 1: Генеративные сети</center></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение\n",
    "\n",
    "Не все же нам MNIST генерировать. Давайте посмотрим, как генеративные модели могут использоваться не только для развлечения. Поехали!\n",
    "\n",
    "Немного вступления и мотивации, для чего мы хотим обучать модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAGIC – Major Atmospheric Gamma Imaging Cherenkov Telescope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAGIC (Major Atmospheric Gamma Imaging Cherenkov) - это система, состоящая из двух черенковских телескопов диаметром 17 м. Они предназначены для наблюдения гамма-лучей от галактических и внегалактических источников в диапазоне очень высоких энергий (от 30 ГэВ до 100 ТэВ). \n",
    "\n",
    "MAGIC позволил открыть и исследовать новые классы источников гамма-излучения, таких как, например, пульсары и гамма-всплески (GRB).\n",
    "\n",
    "<center><img src=\"img/magic1.jpg\" width=\"1000\"></center>\n",
    "\n",
    "Источник: https://magic.mpp.mpg.de/\n",
    "\n",
    "Youtube video: https://youtu.be/mjcDSR2vSU8\n",
    "\n",
    "#### Ок, давайте зафиксируем. Какой-то крутой телескоп позволяет открыть новые виды излучения. Идем дальше."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Частицы из космоса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Космические частицы, $\\gamma$-кванты (фотоны) и адроны (протоны), взаимодействуют с атмосферой и порождают ливни вторичных частиц. Двигаясь с околосветовой скоростью, эти частицы излучают Черенковское излучение. Телескопы фотографируют это излучение. \n",
    "#### По фотографиям можно определить тип частицы из космоса: фотон или протон. Знакомая формулировка задачи, не правда ли?\n",
    "\n",
    "<center><img src=\"img/shower.jpg\" width=\"500\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фотографии"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача атмосферного черенковского телескопа - получить изображение ливня путем измерения черенковского света от частиц ливня. Это изображение представляет собой геометрическую проекцию ливня на детектор. Для анализа этих изображений были введены параметры изображения или так называемые параметры Хилласа. Ниже пример такой фотографии.\n",
    "\n",
    "<center><img src=\"img/geo.jpg\" width=\"400\"></center>\n",
    "\n",
    "#### Итак, каждая фотография описывается набором параметров, которые за нас считает телесоп. А что там с двумя видами частиц?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фотоны vs адронов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изображения для $\\gamma$-квантов (фотонов) и адронов (протонов) отличаются по форме кластеров. Астрономы используют модели машинного обучения для классификации этих изображений. Получение каждого такого изображения - дорогое удовольствие!\n",
    "\n",
    "\n",
    "<center><img src=\"img/gamma_p.png\" width=\"600\"></center>\n",
    "\n",
    "Для обучения моделей ученые искусственно генерируют такие изображения для каждого типа частиц с помощью сложных физических симуляторов. \n",
    "\n",
    "#### Итак, давайте сэкономим денег для ученых и сгенерируем хороших фотографий разных частиц. Используем для этого GAN и диффузионные модели!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Будем использовать данные телескопа MAGIC из UCI репозитория https://archive.ics.uci.edu/ml/datasets/MAGIC+Gamma+Telescope. Каждый объект в данных - параметры одного изображения кластера и метка этого кластера (фотон или адрон):\n",
    "\n",
    "\n",
    "0. Length: major axis of ellipse [mm]\n",
    "1. Width: minor axis of ellipse [mm]\n",
    "2. Size: 10-log of sum of content of all pixels [in #phot]\n",
    "3. Conc: ratio of sum of two highest pixels over fSize [ratio]\n",
    "4. Conc1: ratio of highest pixel over fSize [ratio]\n",
    "5. Asym: distance from highest pixel to center, projected onto major axis [mm]\n",
    "6. M3Long: 3rd root of third moment along major axis [mm]\n",
    "7. M3Trans: 3rd root of third moment along minor axis [mm]\n",
    "8. Alpha: angle of major axis with vector to origin [deg]\n",
    "9. Dist: distance from origin to center of ellipse [mm]\n",
    "10. class: g,h # gamma (signal), hadron (background)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# read data\n",
    "names = np.array(\n",
    "    [\n",
    "        \"Length\",\n",
    "        \"Width\",\n",
    "        \"Size\",\n",
    "        \"Conc\",\n",
    "        \"Conc1\",\n",
    "        \"Asym\",\n",
    "        \"M3Long\",\n",
    "        \"M3Trans\",\n",
    "        \"Alpha\",\n",
    "        \"Dist\",\n",
    "        \"class\",\n",
    "    ]\n",
    ")\n",
    "data = pd.read_csv(\"data/magic04.data\", header=None)\n",
    "data.columns = names\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Постановка задачи\n",
    "\n",
    "Ваша задача заключается в том, чтобы с помощью генеративно-состязательных сетей научиться генерировать параметры кластеров на изображениях телескопа для каждого типа частиц (фотона или адрона):\n",
    "\n",
    "- $X$ - матрица реальных объектов, которые нужно начиться генерировать;\n",
    "- $y$ - метки классов, которые будем использовать как условие при генерации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# параметры кластеров на изображениях\n",
    "X = data[names[:-1]].values\n",
    "X = np.abs(X)\n",
    "\n",
    "# метки классов\n",
    "labels = data[names[-1]].values\n",
    "y = np.ones((len(labels), 1))\n",
    "y[labels == \"h\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# примеры\n",
    "X[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# примеры\n",
    "y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# все возможные значения\n",
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Визуализация данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Каждое изображение описывается 10 параметрами. Давайте построим распределения значений каждого параметра для каждого типа частиц."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hists(X1, X2, names, label1, label2, bins=np.linspace(-3, 3, 61)):\n",
    "    plt.figure(figsize=(5 * 4, 5 * 2))\n",
    "    for i in range(X1.shape[1]):\n",
    "        plt.subplot(3, 4, i + 1)\n",
    "        plt.grid()\n",
    "        plt.hist(X1[:, i], bins=bins, alpha=0.3, label=label1, color=\"C4\")\n",
    "        plt.hist(X2[:, i], bins=bins, alpha=0.3, label=label2, color=\"C0\")\n",
    "        plt.xlabel(names[i], size=14)\n",
    "        plt.legend(loc=\"best\")\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hists(\n",
    "    X[y[:, 0] == 0], X[y[:, 0] == 1], names, label1=\"Hadrons\", label2=\"Photons\", bins=50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Из графика видим, что распределения для многих признаков имеют тяжелые хвосты. Это делает обучение генеративных моделей тяжелее. Поэтому нужно как-то преобразовать данные, чтобы убрать эти тяжелые хвосты."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучающая и тестовая выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train / test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify = y, test_size=0.5, shuffle = True, random_state = 11\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 1 (0.2 балла)\n",
    "\n",
    "Проиллюстрируйте распределение y внутри train и test выборки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 2 (0.8 балл)\n",
    "\n",
    "Используя функцию `sklearn.preprocessing.QuantileTransformer` трансформируйте входные данные `X_train` и `X_test`. Это преобразование делает так, чтобы распределение каждого параметра было нормальным. Описание функции доступно по [ссылке](http://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.QuantileTransformer.html). Используйте значение параметра `output_distribution='normal'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE IS HERE ######\n",
    "X_train = ...\n",
    "X_test = ...\n",
    "### THE END OF YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hists(\n",
    "    X_train[y_train[:, 0] == 0],\n",
    "    X_train[y_train[:, 0] == 1],\n",
    "    names,\n",
    "    label1=\"Hadrons\",\n",
    "    label2=\"Photons\",\n",
    "    bins=50,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hists(X_train, X_test, names, label1=\"Train\", label2=\"Test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditional WGAN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем использовать `Conditional WGAN`, который изображен на рисунке. В качестве условия `y` мы будем использовать метку класса: **0** - адрон, **1** - фотон. Таким образом, мы будем сообщать генератору для какой частицы нужно генерировать параметры изображения. \n",
    "\n",
    "<center><img src=\"img/cgan.png\" width=\"800\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генератор $\\hat{x} = G(z, y)$ будет принимать на вход шумовой вектор $z$ и вектор условий $y$, а выдавать будет сгенерированный (фейковый) вектор параметров $\\hat{x}$. \n",
    "\n",
    "Дискриминатор $D(x, y)$ будет принимать на вход вектор параметров $x$ и вектор условий $y$, а возвращать будет рациональное число.\n",
    "\n",
    "Обучать `Conditional WGAN` будем с такой функцией потерь:\n",
    "\n",
    "$$L(G, D) = -\\frac{1}{n} \\sum_{x_i \\in X, y_i \\in y} D(x_i, y_i) + -\\frac{1}{n} \\sum_{z_i \\in Z, y_i \\in y} D(G(z_i, y_i), y_i) \\to \\max_G \\min_D$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 3 (0.75 балла)\n",
    "\n",
    "Реализуйте нейронную сеть для генератора со следующими слоями:\n",
    "- Полносвязный слой со 100 нейронами;\n",
    "- Слой батч-нормализации;\n",
    "- ReLU функцию активации;\n",
    "- Полносвязный слой со 100 нейронами;\n",
    "- Слой батч-нормализации;\n",
    "- ReLU функцию активации;\n",
    "- Выходной слой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super(Generator, self).__init__()\n",
    "\n",
    "        ### YOUR CODE IS HERE ######\n",
    "        \n",
    "        ### THE END OF YOUR CODE ###\n",
    "\n",
    "    def forward(self, z, y):\n",
    "        zy = torch.cat((z, y), dim=1)\n",
    "        return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 4 (0.5 балл)\n",
    "\n",
    "Реализуйте функцию для генерации новый объектов $X$ по вектору условий $y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(generator, y, latent_dim):\n",
    "    ### YOUR CODE IS HERE ######\n",
    "    X_fake = ...\n",
    "    ### THE END OF YOUR CODE ###\n",
    "    return X_fake  # numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 5 (0.75 балла)\n",
    "\n",
    "Реализуйте нейронную сеть для дискриминатора со следующими слоями:\n",
    "- Полносвязный слой со 100 нейронами;\n",
    "- ReLU функцию активации;\n",
    "- Полносвязный слой со 100 нейронами;\n",
    "- ReLU функцию активации;\n",
    "- Выходной слой.\n",
    "\n",
    "Какая функция активации должна быть в конце работы модели и почему? А она вообще тут должна быть? Обоснуйте свой выбор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, n_inputs):\n",
    "        super(Discriminator, self).__init__()\n",
    "\n",
    "        ### YOUR CODE IS HERE ######\n",
    "\n",
    "        ### THE END OF YOUR CODE ###\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        xy = torch.cat((x, y), dim=1)\n",
    "        return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6 (0.5 балла)\n",
    "\n",
    "Реализуйте функцию, которая принимала бы на вход набор сгенерированных и настоящих объектов, разбивала на train и test с учетом баланса классов (real и fake объектов), с соотношением 3 к 1, обучала модель линейной регрессии и градиентного бустинга, которые учились бы отличать настоящие объекты от фальшивых, после чего выводила бы accuracy score на отложенной выборке у обоих моделей.\n",
    "\n",
    "Ответьте на вопрос: какое значение accuracy score нас бы удовлетворило больше всего? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def other_agent_score(X_real, y_real, X_fake, y_fake):\n",
    "    ### YOUR CODE IS HERE ######\n",
    "    lin_reg_score = ...\n",
    "    boosting_score = ...\n",
    "    ### THE END OF YOUR CODE ###\n",
    "    print('Linear regression score: ' + str(lin_reg_score))\n",
    "    print('Boosting score: ' + str(boosting_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 7 (1.5 балла)\n",
    "\n",
    "Реализуйте класс для обучения генеративной модели.\n",
    "\n",
    "- Подсказка 1: не забывайте ограничивать веса дискриминатора. Для этого используйте `p.data.clamp_(-0.01, 0.01)`, где `p` веса дискриминатора.\n",
    "- Подсказка 2: `n_critic` - число итераций обучения дискриминатора на одну итерацию обучения генератора.\n",
    "- Подсказка 3: Используйте `X_tensor = torch.tensor(X_numpy, dtype=torch.float, device=DEVICE)` для перевода numpy в тензор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fitter(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        generator,\n",
    "        discriminator,\n",
    "        batch_size = 32,\n",
    "        n_epochs = 10,\n",
    "        latent_dim = 1,\n",
    "        lr = 0.0001,\n",
    "        n_critic=5,\n",
    "    ):\n",
    "\n",
    "        self.generator = generator\n",
    "        self.discriminator = discriminator\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.latent_dim = latent_dim\n",
    "        self.lr = lr\n",
    "        self.n_critic = n_critic\n",
    "\n",
    "        self.opt_gen = torch.optim.RMSprop(self.generator.parameters(), lr=self.lr)\n",
    "        self.opt_disc = torch.optim.RMSprop(self.discriminator.parameters(), lr=self.lr)\n",
    "\n",
    "        self.generator.to(DEVICE)\n",
    "        self.discriminator.to(DEVICE)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # numpy to tensor\n",
    "        X_real = torch.tensor(X, dtype=torch.float, device=DEVICE)\n",
    "        y_cond = torch.tensor(y, dtype=torch.float, device=DEVICE)\n",
    "\n",
    "        # tensor to dataset\n",
    "        dataset_real = TensorDataset(X_real, y_cond)\n",
    "\n",
    "        # Turn on training\n",
    "        self.generator.train(True)\n",
    "        self.discriminator.train(True)\n",
    "\n",
    "        self.loss_history = []\n",
    "\n",
    "        # Fit GAN\n",
    "        for epoch in range(self.n_epochs):\n",
    "            for i, (real_batch, cond_batch) in enumerate(\n",
    "                DataLoader(dataset_real, batch_size=self.batch_size, shuffle=True)\n",
    "            ):\n",
    "\n",
    "                ### YOUR CODE IS HERE ######\n",
    "\n",
    "                ...\n",
    "\n",
    "                ### THE END OF YOUR CODE ###\n",
    "\n",
    "            # caiculate and store loss after an epoch\n",
    "            Z_noise = torch.normal(0, 1, (len(X_real), self.latent_dim))\n",
    "            X_fake = self.generator(Z_noise, y_cond)\n",
    "            loss_epoch = torch.mean(self.discriminator(X_real, y_cond)) - torch.mean(\n",
    "                self.discriminator(X_fake, y_cond)\n",
    "            )\n",
    "            self.loss_history.append(loss_epoch.detach().cpu())\n",
    "            \n",
    "            # Создайте выборку из 1000 объектов из X_train и 1000 сгенерированных объектов \n",
    "            # И запустите работу фукнции other_agent_score\n",
    "            \n",
    "            ### YOUR CODE IS HERE ######\n",
    "            ...\n",
    "            ### THE END OF YOUR CODE ###\n",
    "            \n",
    "        # Turn off training\n",
    "        self.generator.train(False)\n",
    "        self.discriminator.train(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение\n",
    "Обучим модель на данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "latent_dim = 10\n",
    "generator = Generator(n_inputs=latent_dim + y.shape[1], n_outputs=X_train.shape[1])\n",
    "discriminator = Discriminator(n_inputs=X_train.shape[1] + y.shape[1])\n",
    "\n",
    "fitter = Fitter(\n",
    "    generator,\n",
    "    discriminator,\n",
    "    batch_size=50,\n",
    "    n_epochs=100,\n",
    "    latent_dim=latent_dim,\n",
    "    lr=0.0001,\n",
    "    n_critic=5,\n",
    ")\n",
    "fitter.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WGAN learning curve\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(fitter.loss_history)\n",
    "plt.xlabel(\"Epoch Number\", size=14)\n",
    "plt.ylabel(\"Loss Function\", size=14)\n",
    "plt.xticks(size=14)\n",
    "plt.yticks(size=14)\n",
    "plt.title(\"Conditional WGAN Learning Curve\", size=14)\n",
    "plt.grid(b=1, linestyle=\"--\", linewidth=0.5, color=\"0.5\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 8 (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь сгенерируем фейковые матрицы `X_fake_train` и `X_fake_test`. Сравним их с матрицами реальных объектов `X_train` и `X_test`. Перед сравнением результатов сделайте обратное квантильное преобразование с помощью трансформера, который вы обучили в задании 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE IS HERE ######\n",
    "\n",
    "### THE END OF YOUR CODE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fake_train = generate(fitter.generator, y_train, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hists(X_train, X_fake_train, names, label1=\"Real\", label2=\"Fake\", bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fake_test = generate(fitter.generator, y_test, latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hists(X_test, X_fake_test, names, label1=\"Real\", label2=\"Fake\", bins=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вывод: \n",
    "Визуально мы видим сходство реальных и фейковых данных. Однако это только проекции 10-мерных объектов на одну ось."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Измерение качества генерации\n",
    "\n",
    "<center><img src=\"img/clf.png\" width=\"600\"></center>\n",
    "\n",
    "Измерим сходство распределений классификатором."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# собираем реальный и фейковые матрицы в одну\n",
    "XX_train = np.concatenate((X_fake_train, X_train), axis=0)\n",
    "XX_test = np.concatenate((X_fake_test, X_test), axis=0)\n",
    "\n",
    "yy_train = np.array([0] * len(X_fake_train) + [1] * len(X_train))\n",
    "yy_test = np.array([0] * len(X_fake_test) + [1] * len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# обучаем классификатор\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(XX_train, yy_train)\n",
    "\n",
    "# получаем прогнозы\n",
    "yy_test_proba = clf.predict_proba(XX_test)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "auc = roc_auc_score(yy_test, yy_test_proba)\n",
    "print(\"ROC AUC = \", auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 9 (0.5 балла)\n",
    "\n",
    "Опишите ваш эксперимент. Как вы оцениваете полученные результаты? Как вы думаете, какое значение ROC AUC нас удовлетворяет больше всего? Почему?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Диффузионные модели.\n",
    "\n",
    "Давайте теперь проведем такой же экперимент с простой диффузионной моделью."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 10 (0.5 балла)\n",
    "\n",
    "Реализуйте фукнцию из семинара для зашумления данных, адаптировав ее под наш тип данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt(x, amount):\n",
    "    ### YOUR CODE IS HERE ######\n",
    "    x = ...\n",
    "    ### THE END OF YOUR CODE ###\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Добавим sсheduler, он пригодится вам при обучении модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_scheduler = DDPMScheduler(num_train_timesteps=1000)\n",
    "plt.plot(noise_scheduler.alphas_cumprod.cpu() ** 0.5, label=r\"${\\sqrt{\\bar{\\alpha}_t}}$\")\n",
    "plt.plot((1 - noise_scheduler.alphas_cumprod.cpu()) ** 0.5, label=r\"$\\sqrt{(1 - \\bar{\\alpha}_t)}$\")\n",
    "plt.legend(fontsize=\"x-large\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 11 (0.5 балла)\n",
    "\n",
    "Реализуйте нейронную сеть. В качетсве архитектуры можете взять модель генератора. В процессе экспериментов попробуйте изменять архитектуру модели для улучшения качества сгенерированных объектов (Кстати, как вы будете качество измерять?). \n",
    "\n",
    "- Полносвязный слой со 100 нейронами;\n",
    "- Слой батч-нормализации;\n",
    "- ReLU функцию активации;\n",
    "- Полносвязный слой со 100 нейронами;\n",
    "- Слой батч-нормализации;\n",
    "- ReLU функцию активации;\n",
    "- Выходной слой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionGenerator(nn.Module):\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super(DiffusionGenerator, self).__init__()\n",
    "\n",
    "        ### YOUR CODE IS HERE ######\n",
    "        \n",
    "        ### THE END OF YOUR CODE ###\n",
    "\n",
    "    def forward(self, z, y):\n",
    "        zy = torch.cat((z, y), dim=1)\n",
    "        return ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 12 (0.5 балла)\n",
    "\n",
    "Напишите функцию для генерации нового объекта с помощью обученной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_with_diffusion(model, y, latent_dim, sheduler):\n",
    "    ### YOUR CODE IS HERE ######\n",
    "    X_fake = ...\n",
    "    ### THE END OF YOUR CODE ###\n",
    "    return X_fake  # numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 13 (2 балла)\n",
    "\n",
    "Напишите класс обучения диффузионной модели и обучите модель, после чего опишите полученные результаты. В качестве подсказки - опирайтесь на семинар по диффузионным моделям. Вы можете изменять некоторые части кода для вашего удобства, но оставляйте в таком случаи комментарии, пожалуйста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiffusionFitter(object):\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        batch_size = 32,\n",
    "        n_epochs = 10,\n",
    "        latent_dim = 1,\n",
    "        lr = 0.0001,\n",
    "        n_critic=5,\n",
    "    ):\n",
    "\n",
    "        self.model = generator\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs = n_epochs\n",
    "        self.latent_dim = latent_dim\n",
    "        self.lr = lr\n",
    "        self.n_critic = n_critic\n",
    "\n",
    "        self.opt_gen = torch.optim.RMSprop(self.model.parameters(), lr=self.lr)\n",
    "\n",
    "        self.model.to(DEVICE)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        # numpy to tensor\n",
    "        X_real = torch.tensor(X, dtype=torch.float, device=DEVICE)\n",
    "        y_cond = torch.tensor(y, dtype=torch.float, device=DEVICE)\n",
    "\n",
    "        # tensor to dataset\n",
    "        dataset_real = TensorDataset(X_real, y_cond)\n",
    "\n",
    "        # Turn on training\n",
    "        self.model.train(True)\n",
    "\n",
    "        self.loss_history = []\n",
    "\n",
    "        # Fit GAN\n",
    "        for epoch in range(self.n_epochs):\n",
    "            loss_epoch = 0\n",
    "            for i, (real_batch, cond_batch) in enumerate(\n",
    "                DataLoader(dataset_real, batch_size=self.batch_size, shuffle=True)\n",
    "            ):\n",
    "\n",
    "                ### YOUR CODE IS HERE ######\n",
    "\n",
    "                ...\n",
    "                \n",
    "                loss_epoch += ...\n",
    "                \n",
    "                ### THE END OF YOUR CODE ###\n",
    "\n",
    "            # caiculate and store loss after an epoch\n",
    "            \n",
    "            self.loss_history.append(loss_epoch)\n",
    "            \n",
    "            # Создайте выборку из 1000 объектов из X_train и 1000 сгенерированных объектов \n",
    "            # И запустите работу фукнции other_agent_score\n",
    "            \n",
    "            ### YOUR CODE IS HERE ######\n",
    "            ...\n",
    "            ### THE END OF YOUR CODE ###\n",
    "            \n",
    "        # Turn off training\n",
    "        self.model.train(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "latent_dim = 10\n",
    "model = DiffusionGenerator(n_inputs=latent_dim + y.shape[1], n_outputs=X_train.shape[1])\n",
    "\n",
    "diffusionFitter = DiffusionFitter(\n",
    "    model,\n",
    "    batch_size=50,\n",
    "    n_epochs=100,\n",
    "    latent_dim=latent_dim,\n",
    "    lr=0.0001,\n",
    "    n_critic=5,\n",
    ")\n",
    "diffusionFitter.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffusion learning curve\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.plot(diffusionFitter.loss_history)\n",
    "plt.xlabel(\"Epoch Number\", size=14)\n",
    "plt.ylabel(\"Loss Function\", size=14)\n",
    "plt.xticks(size=14)\n",
    "plt.yticks(size=14)\n",
    "plt.title(\"Conditional diffusing model Learning Curve\", size=14)\n",
    "plt.grid(b=1, linestyle=\"--\", linewidth=0.5, color=\"0.5\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 14 (0.5 балла)\n",
    "По аналогии с прошлым экспериментом с GAN моделью сгенерируйте выборку фейковых объектов равную размеру тестовой выборки и обучите градиентный бустинг. Обучите модель отличать реальные объекты от фейковых, после чего расчитайте метрики ROC-AUC и accuracy score. Какие получились результаты? Как вы их оцениваете? А в сравнении с GAN моделью?"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Отзыв\n",
    "\n",
    "Поздравляю! Вы дошли до конца. Оставьте ваш отзыв ячейкой ниже или отправьте его в канал курса, нам будет очень интересно!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
